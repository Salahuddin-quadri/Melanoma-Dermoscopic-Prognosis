{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Melanoma Dermoscopic Prognosis - Colab Training Notebook\n",
        "\n",
        "This notebook sets up the environment, downloads data from Google Drive, and trains the model using `main.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy==1.26.4 pandas==2.2.2 scikit-learn==1.4.2 scipy==1.11.4\n",
        "!pip install matplotlib==3.8.4 seaborn==0.13.2 opencv-python==4.10.0.84 Pillow==10.4.0\n",
        "!pip install tqdm==4.66.4 ipywidgets==8.1.3 imbalanced-learn==0.12.3\n",
        "!pip install gdown  # For downloading from Google Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Clone the repository (replace with your actual GitHub repo URL)\n",
        "# If you need to get the repo URL, you can check the git remote in your local repo:\n",
        "# git remote get-url origin\n",
        "repo_url = \"https://github.com/yourusername/Melanoma-Dermoscopic-Prognosis.git\"  # UPDATE THIS\n",
        "repo_name = \"Melanoma-Dermoscopic-Prognosis\"\n",
        "\n",
        "# Check if we're already in the repo directory\n",
        "if os.path.exists(\"src/main.py\"):\n",
        "    print(\"Already in repository directory. Skipping clone.\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "elif os.path.exists(repo_name):\n",
        "    print(f\"Repository {repo_name} already exists. Changing to it.\")\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "else:\n",
        "    # Clone the repository\n",
        "    get_ipython().system(f'git clone {repo_url}')\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"Cloned and changed to: {os.getcwd()}\")\n",
        "\n",
        "# Verify we're in the right place\n",
        "assert os.path.exists(\"src/main.py\"), \"src/main.py not found! Check repository structure.\"\n",
        "print(\"✓ Repository setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Download Data from Google Drive\n",
        "\n",
        "**Note:** If the Google Drive folder is not publicly accessible, you may need to:\n",
        "1. Make the folder shareable (anyone with link can view), OR\n",
        "2. Use the Google Drive mounting method below (requires authentication)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive folder ID\n",
        "drive_folder_id = \"1P9YYZJbTQsadjvwXRvKTMUdm_TXAMR9t\"\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Method 1: Using gdown (requires folder to be publicly accessible)\n",
        "# Uncomment and use this if the folder is public:\n",
        "get_ipython().system(f'gdown --folder https://drive.google.com/drive/folders/{drive_folder_id} -O data --remaining-ok')\n",
        "\n",
        "# Method 2: Mount Google Drive (if you have access to the folder)\n",
        "# Uncomment the following lines if Method 1 doesn't work:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# # Then copy files from your Drive folder to the data directory\n",
        "# import shutil\n",
        "# # Adjust the path below to match your Drive folder structure\n",
        "# # shutil.copytree('/content/drive/MyDrive/your_folder_path', 'data', dirs_exist_ok=True)\n",
        "\n",
        "print(\"\\nData download complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data files\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path(\"data\")\n",
        "print(\"Data directory contents:\")\n",
        "for item in data_dir.rglob(\"*\"):\n",
        "    if item.is_file():\n",
        "        print(f\"  {item.relative_to(data_dir)}\")\n",
        "\n",
        "# Check for required files\n",
        "required_files = [\"merged_dataset.csv\", \"meta_data.csv\"]\n",
        "for file in required_files:\n",
        "    file_path = data_dir / file\n",
        "    if file_path.exists():\n",
        "        print(f\"✓ Found: {file}\")\n",
        "    else:\n",
        "        print(f\"✗ Missing: {file}\")\n",
        "\n",
        "# Check for images folder\n",
        "images_dir = data_dir / \"images\"\n",
        "if images_dir.exists():\n",
        "    num_images = len(list(images_dir.glob(\"*\")))\n",
        "    print(f\"✓ Found images folder with {num_images} items\")\n",
        "else:\n",
        "    print(\"✗ Missing images folder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Verify Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Check PyTorch\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Check repository structure\n",
        "print(\"\\nRepository structure:\")\n",
        "print(f\"  Current directory: {os.getcwd()}\")\n",
        "print(f\"  src/main.py exists: {os.path.exists('src/main.py')}\")\n",
        "print(f\"  requirements.txt exists: {os.path.exists('requirements.txt')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Training Configuration\n",
        "\n",
        "Configure your training parameters here. Adjust as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "config = {\n",
        "    \"metadata_path\": \"data/merged_dataset.csv\",\n",
        "    \"image_dir\": \"data/images\",\n",
        "    \"mode\": \"train\",\n",
        "    \"model_type\": \"dino\",  # or \"resnet\"\n",
        "    \"epochs\": 30,\n",
        "    \"batch_size\": 16,\n",
        "    \"image_size\": [384, 384],\n",
        "    \"output_dir\": \"outputs\",\n",
        "    \"task\": \"classification\",  # or \"regression\"\n",
        "    \"multitask\": False,  # Set to True for dual-head (classification + regression)\n",
        "    \"loss_alpha\": 0.5,  # Weight for classification loss in multitask\n",
        "    \"cls_loss_type\": \"weighted_bce\",  # \"bce\", \"weighted_bce\", or \"focal\"\n",
        "    \"focal_gamma\": 2.0,  # For focal loss\n",
        "    \"fusion_type\": \"cross_attention\",  # \"cross_attention\" or \"concat\"\n",
        "    \"freeze_backbone_layers\": 7,  # Number of ViT layers to freeze\n",
        "    \"val_size\": 0.15,\n",
        "    \"test_size\": 0.15,\n",
        "    \"device\": \"auto\",  # \"cuda\", \"cpu\", or \"auto\"\n",
        "}\n",
        "\n",
        "# Optional: DINO checkpoint path (if you have a pretrained checkpoint)\n",
        "# config[\"dino_checkpoint\"] = \"dino_v3/outputs_dino/checkpoints/best.pt\"\n",
        "\n",
        "print(\"Training configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build command arguments\n",
        "args_list = []\n",
        "for key, value in config.items():\n",
        "    if value is not None and value != \"\":\n",
        "        if isinstance(value, bool):\n",
        "            if value:\n",
        "                args_list.append(f\"--{key}\")\n",
        "        elif isinstance(value, list):\n",
        "            args_list.append(f\"--{key}\")\n",
        "            args_list.extend([str(v) for v in value])\n",
        "        else:\n",
        "            args_list.append(f\"--{key}\")\n",
        "            args_list.append(str(value))\n",
        "\n",
        "# Convert to string\n",
        "args_str = \" \".join(args_list)\n",
        "\n",
        "print(f\"Running training with command:\")\n",
        "print(f\"python -m src.main {args_str}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run training\n",
        "get_ipython().system(f'python -m src.main {args_str}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Check Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List output files\n",
        "output_dir = Path(config[\"output_dir\"])\n",
        "if output_dir.exists():\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "    print(\"\\nContents:\")\n",
        "    for item in output_dir.rglob(\"*\"):\n",
        "        if item.is_file():\n",
        "            size = item.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "            print(f\"  {item.relative_to(output_dir)} ({size:.2f} MB)\")\n",
        "    \n",
        "    # Check for checkpoints\n",
        "    checkpoint_dir = output_dir / \"checkpoints\"\n",
        "    if checkpoint_dir.exists():\n",
        "        print(\"\\nCheckpoints:\")\n",
        "        for ckpt in checkpoint_dir.glob(\"*.pt\"):\n",
        "            size = ckpt.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  {ckpt.name} ({size:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"Output directory {output_dir} not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Download Results to Local Machine\n",
        "\n",
        "After training, you can download the checkpoints and logs to your local machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zip file of outputs (optional)\n",
        "# !zip -r outputs.zip {config['output_dir']}\n",
        "# print(\"Outputs zipped to outputs.zip. You can download it from the Colab file browser.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
